import express from "express";
import bodyParser from "body-parser";
import cors from "cors";
import OpenAI from "openai";
import { addToQueue } from "./queue.js";

const app = express();
const port = process.env.PORT || 5000;

app.use(bodyParser.json());
app.use(cors());

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ðŸ”¹ ìœ ì €ë³„ ëŒ€í™” ì €ìž¥ìš© (ê°„ë‹¨ížˆ ë©”ëª¨ë¦¬ ë²„ì „, í•„ìš”í•˜ë©´ DBë¡œ í™•ìž¥ ê°€ëŠ¥)
const conversations = {};

app.post("/gpt", async (req, res) => {
  try {
    const { userId, message } = req.body;  // âœ… userId ê¼­ ë³´ë‚´ì•¼ í•¨ (í”Œë ˆì´ì–´ ID ë“±)
    if (!userId) {
      return res.status(400).json({ error: "userId is required" });
    }

    // ìœ ì €ë³„ ëŒ€í™” ë°°ì—´ ì´ˆê¸°í™”
    if (!conversations[userId]) {
      conversations[userId] = [
        { role: "system", content: "ë„ˆëŠ” í•™êµ ì¹œêµ¬ ì—­í• ì˜ NPCì•¼. ì¹œê·¼í•˜ê³  ê°„ë‹¨í•˜ê²Œ ëŒ€ë‹µí•´." }
      ];
    }

    // ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
    conversations[userId].push({ role: "user", content: message });

    // GPT í˜¸ì¶œ
    const response = await addToQueue(() =>
      client.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: conversations[userId],  // ëŒ€í™” ì „ì²´ë¥¼ ë„˜ê¹€
      })
    );

    const aiMessage = response.choices[0].message.content;

    // AI ì‘ë‹µë„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    conversations[userId].push({ role: "assistant", content: aiMessage });

    res.json({ reply: aiMessage });
  } catch (error) {
    console.error("OpenAI API Error:", error.message);
    res.status(500).json({ error: "Failed to fetch response from OpenAI" });
  }
});

app.listen(port, () => {
  console.log(`ðŸš€ Server running on http://localhost:${port}`);
});
